{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14979459",
   "metadata": {},
   "source": [
    "# Fast Gradient Sign Method (FGSM) in AI Image Compression\n",
    "It is a *single-step* computationally efficient attack.  \n",
    "1. **Mathematical Formulations**\n",
    "The core idea is that to push the data into direction that **maximizes the loss function**. The formula that are used are:  \n",
    "$$x_{adv} = x+\\epsilon \\text{sign} (\\nabla_x J(\\theta, x, y)) =x+ \\frac{\\epsilon}{N}\\text{sign} (\\nabla_x \\|x- y\\|_F^2) $$\n",
    "where \n",
    "- $x$: The original, clean input image (a tensor of pixel values).  \n",
    "- $y=x_{hat}$: The decompressed of image $x$: $f(x)[{x_{hat}}]$, and $f$ is the compression model.  \n",
    "- $J(θ, x, y)$: The loss function (e.g., mse Loss) of the model.\n",
    "\n",
    "- $θ$: The parameters (weights) of the model. Crucially, these are held constant. We are not learning the model; we are attacking it.\n",
    "\n",
    "- $∇ₓ J(\\cdots)$: The gradient of the loss function with respect to the input image x. This tells us the direction in the input space that, if we follow it, will increase the loss the most.\n",
    "\n",
    "- $\\text{sign}(\\cdots)$: This function takes the gradient and converts each of its components to either +1, -1, or 0. This is done because we are only interested in the direction of the steepest ascent, not its magnitude. Using the sign also ensures that the perturbation for each pixel will be exactly +ε or -ε, which is optimal for the L∞ constraint.\n",
    "\n",
    "- $ε$ (epsilon): A small, scalar value that is the attack's \"budget.\" It defines the maximum amount any pixel is allowed to change. This keeps the perturbation imperceptible (on a [0,1] scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54b7a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Data dir: /mnt/d/github/Adversarial_Attack_Image_compression/kodim\n",
      "Output dir: /mnt/d/github/Adversarial_Attack_Image_compression/outputs_fgsm\n"
     ]
    }
   ],
   "source": [
    "# Environment setup and imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "# compressai\n",
    "try:\n",
    "    from compressai.zoo import cheng2020_anchor\n",
    "    ## Load pretrained AI image compression models\n",
    "    # from compressai.zoo import cheng2020_anchor\n",
    "    from compressai.zoo import models\n",
    "except Exception as e:\n",
    "    raise SystemExit(\"compressai is required. Install via: pip install compressai[full]\")\n",
    "\n",
    "# device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# Paths\n",
    "NB_DIR = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "PROJECT_ROOT = NB_DIR.parent\n",
    "DATA_DIR = (PROJECT_ROOT / \"kodim\").resolve()\n",
    "OUTPUT_DIR = (PROJECT_ROOT / \"outputs_fgsm\").resolve()\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Data dir:\", DATA_DIR)\n",
    "print(\"Output dir:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a48c01",
   "metadata": {},
   "source": [
    "## Load AI Image compression model: compressai models\n",
    "- Link to the model https://github.com/InterDigitalInc/CompressAI\n",
    "- Model name: ```cheng2020-anchor``` with quality 6, original papers: \n",
    "```bibtex\n",
    "    @inproceedings{cheng2020image,\n",
    "    title={Learned Image Compression with Discretized Gaussian Mixture\n",
    "    Likelihoods and Attention Modules},\n",
    "    author={Cheng, Zhengxue and Sun, Heming and Takeuchi, Masaru and Katto,\n",
    "    Jiro},\n",
    "    booktitle= \"Proceedings of the IEEE Conference on Computer Vision and\n",
    "    Pattern Recognition (CVPR)\",\n",
    "    year={2020}}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c77d1cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing FGSM attack...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"cheng2020-anchor\"\n",
    "\n",
    "# Computational device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dynamically retrieve the model class\n",
    "quality = 6\n",
    "model_class = models[model_name]\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "# Set compression-decompression quality for AI image compression \n",
    "model = model_class(quality=quality, pretrained=True).to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Loading image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load and preprocess the image\n",
    "def load_image(image_path):\n",
    "    \"\"\"Load image and convert to tensor\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    return image_tensor, image\n",
    "\n",
    "# FGSM Attack\n",
    "def fgsm_attack(model, x, epsilon, criterion, y_comp=None):\n",
    "    \"\"\"\n",
    "    Perform FGSM attack on the compression model\n",
    "    \n",
    "    Args:\n",
    "        model: The compression model\n",
    "        x: Original input image tensor\n",
    "        epsilon: Attack strength (perturbation budget)\n",
    "        criterion: Loss function\n",
    "        y_comp: Optional target for the compressed representation\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode but enable gradients for input\n",
    "    model.eval()\n",
    "    \n",
    "    # Enable gradient computation for input\n",
    "    x.requires_grad = True\n",
    "    x_hat = model(x)[\"x_hat\"]\n",
    "    loss = - criterion(x_hat,x)\n",
    "    # Forward pass through compression model\n",
    "    # # Compression models typically return: (output, likelihoods) or similar\n",
    "    # compressed_output = model.compress(x)\n",
    "    \n",
    "    # # If we have a target for the compressed representation, use it\n",
    "    # # Otherwise, we'll maximize the distortion (minimize quality)\n",
    "    # if y_comp is None:\n",
    "    #     # For untargeted attack: maximize the distortion/loss\n",
    "    #     # We can use the bitrate or reconstruction error as loss\n",
    "    #     if isinstance(compressed_output, tuple):\n",
    "    #         # Handle tuple output (common in compressai)\n",
    "    #         output, likelihoods = compressed_output\n",
    "    #         # Use negative bits per pixel as loss to maximize bitrate\n",
    "    #         loss = -torch.log(likelihoods).sum() / (x.shape[2] * x.shape[3] * x.shape[0])\n",
    "    #     else:\n",
    "    #         # Fallback: use MSE between input and decompressed output\n",
    "    #         decompressed = model.decompress(compressed_output)\n",
    "    #         loss = -criterion(decompressed['x_hat'], x)  # Negative to maximize error\n",
    "    # else:\n",
    "    #     # Targeted attack: make compression match y_comp\n",
    "    #     if isinstance(compressed_output, tuple):\n",
    "    #         output, likelihoods = compressed_output\n",
    "    #         loss = criterion(output, y_comp)\n",
    "    #     else:\n",
    "    #         loss = criterion(compressed_output, y_comp)\n",
    "    \n",
    "    # Compute gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get gradient sign\n",
    "    gradient_sign = x.grad.data.sign()\n",
    "    \n",
    "    # Create adversarial example\n",
    "    x_adv = x + epsilon * gradient_sign\n",
    "    \n",
    "    # Clip to valid image range [0, 1]\n",
    "    x_adv = torch.clamp(x_adv, 0, 1)\n",
    "    \n",
    "    # Detach and disable gradients\n",
    "    x_adv = x_adv.detach()\n",
    "    x.requires_grad = False\n",
    "    \n",
    "    return x_adv\n",
    "\n",
    "# PGD Attack\n",
    "def pgd_attack(model, x, epsilon, alpha, num_iter, criterion, y_comp=None, random_start=True):\n",
    "    \"\"\"\n",
    "    Perform PGD attack on the compression model\n",
    "    \n",
    "    Args:\n",
    "        model: The compression model\n",
    "        x: Original input image tensor\n",
    "        epsilon: Maximum perturbation budget\n",
    "        alpha: Step size for each iteration\n",
    "        num_iter: Number of PGD iterations\n",
    "        criterion: Loss function\n",
    "        y_comp: Optional target for compressed representation\n",
    "        random_start: Whether to start from random point within epsilon-ball\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Start from original or random point within epsilon-ball\n",
    "    if random_start:\n",
    "        x_adv = x + torch.empty_like(x).uniform_(-epsilon, epsilon)\n",
    "        x_adv = torch.clamp(x_adv, 0, 1)\n",
    "    else:\n",
    "        x_adv = x.clone()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        x_adv.requires_grad = True\n",
    "        \n",
    "        # Forward pass\n",
    "        # compressed_output = model.compress(x_adv)\n",
    "        x_hat = model(x_adv)[\"x_hat\"]\n",
    "        loss = - criterion(x_hat,x)\n",
    "        # # Calculate loss\n",
    "        # if y_comp is None:\n",
    "        #     # Untargeted attack: maximize distortion\n",
    "        #     if isinstance(compressed_output, tuple):\n",
    "        #         output, likelihoods = compressed_output\n",
    "        #         loss = -torch.log(likelihoods).sum() / (x.shape[2] * x.shape[3] * x.shape[0])\n",
    "        #     else:\n",
    "        #         decompressed = model.decompress(compressed_output)\n",
    "        #         loss = -criterion(decompressed['x_hat'], x)\n",
    "        # else:\n",
    "        #     # Targeted attack\n",
    "        #     if isinstance(compressed_output, tuple):\n",
    "        #         output, likelihoods = compressed_output\n",
    "        #         loss = criterion(output, y_comp)\n",
    "        #     else:\n",
    "        #         loss = criterion(compressed_output, y_comp)\n",
    "        \n",
    "        # Compute gradients\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Get gradient sign\n",
    "        gradient_sign = x_adv.grad.data.sign()\n",
    "        \n",
    "        # Update adversarial example\n",
    "        x_adv = x_adv + alpha * gradient_sign\n",
    "        \n",
    "        # Project back to epsilon-ball around original image\n",
    "        delta = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
    "        x_adv = torch.clamp(x + delta, 0, 1)\n",
    "        \n",
    "        x_adv = x_adv.detach()\n",
    "    \n",
    "    return x_adv\n",
    "\n",
    "# Visualization function\n",
    "def visualize_attack(original, adversarial, original_compressed, adversarial_compressed, epsilon):\n",
    "    \"\"\"Visualize original and adversarial images with their compressed versions\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Convert tensors to numpy for plotting\n",
    "    original_np = original.squeeze(0).cpu().permute(1, 2, 0).numpy()\n",
    "    adversarial_np = adversarial.squeeze(0).cpu().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Plot original and adversarial\n",
    "    axes[0, 0].imshow(original_np)\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(adversarial_np)\n",
    "    axes[0, 1].set_title(f'Adversarial Image (ε={epsilon})')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Plot compressed versions\n",
    "    if 'x_hat' in original_compressed:\n",
    "        orig_comp_np = original_compressed['x_hat'].squeeze(0).cpu().permute(1, 2, 0).numpy()\n",
    "        adv_comp_np = adversarial_compressed['x_hat'].squeeze(0).cpu().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        axes[1, 0].imshow(np.clip(orig_comp_np, 0, 1))\n",
    "        axes[1, 0].set_title('Compressed Original')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        axes[1, 1].imshow(np.clip(adv_comp_np, 0, 1))\n",
    "        axes[1, 1].set_title('Compressed Adversarial')\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    perturbation = torch.abs(adversarial - original)\n",
    "    max_perturbation = perturbation.max().item()\n",
    "    avg_perturbation = perturbation.mean().item()\n",
    "    \n",
    "    print(f\"Attack parameters: ε={epsilon}\")\n",
    "    print(f\"Maximum perturbation: {max_perturbation:.4f}\")\n",
    "    print(f\"Average perturbation: {avg_perturbation:.4f}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Load your model (you already have this)\n",
    "    from compressai.zoo import models\n",
    "    model_name = \"cheng2020-anchor\"\n",
    "    quality = 6\n",
    "    model_class = models[model_name]\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    model = model_class(quality=quality, pretrained=True).to(device)\n",
    "    \n",
    "    # Freeze model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Load image\n",
    "    image_path = \"../kodim/kodim01.png\"\n",
    "    x_original, pil_image = load_image(image_path)\n",
    "    \n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Attack parameters\n",
    "    epsilon = 8/255.0  # Common attack strength\n",
    "    alpha = 2/255.0    # PGD step size\n",
    "    num_iter = 10      # PGD iterations\n",
    "    \n",
    "    print(\"Performing FGSM attack...\")\n",
    "    # FGSM Attack\n",
    "    x_adv_fgsm = fgsm_attack(model, x_original, epsilon, criterion)\n",
    "    \n",
    "    print(\"Performing PGD attack...\")\n",
    "    # PGD Attack\n",
    "    x_adv_pgd = pgd_attack(model, x_original, epsilon, alpha, num_iter, criterion)\n",
    "    \n",
    "    # Compress the images to see the effect\n",
    "    print(\"Compressing images...\")\n",
    "    with torch.no_grad():\n",
    "        # Original compression\n",
    "        comp_original = model.compress(x_original)\n",
    "        decomp_original = model.decompress(comp_original['strings'], comp_original['shape'])\n",
    "        \n",
    "        # FGSM adversarial compression\n",
    "        comp_fgsm = model.compress(x_adv_fgsm)\n",
    "        decomp_fgsm = model.decompress(comp_fgsm['strings'], comp_fgsm['shape'])\n",
    "        \n",
    "        # PGD adversarial compression\n",
    "        comp_pgd = model.compress(x_adv_pgd)\n",
    "        decomp_pgd = model.decompress(comp_pgd['strings'], comp_pgd['shape'])\n",
    "    \n",
    "    # Visualize results\n",
    "    print(\"FGSM Attack Results:\")\n",
    "    visualize_attack(x_original, x_adv_fgsm, decomp_original, decomp_fgsm, epsilon)\n",
    "    \n",
    "    print(\"PGD Attack Results:\")\n",
    "    visualize_attack(x_original, x_adv_pgd, decomp_original, decomp_pgd, epsilon)\n",
    "    \n",
    "    # Calculate quantitative metrics\n",
    "    mse_original = criterion(decomp_original['x_hat'], x_original).item()\n",
    "    mse_fgsm = criterion(decomp_fgsm['x_hat'], x_original).item()\n",
    "    mse_pgd = criterion(decomp_pgd['x_hat'], x_original).item()\n",
    "    \n",
    "    print(f\"\\nReconstruction MSE:\")\n",
    "    print(f\"Original: {mse_original:.6f}\")\n",
    "    print(f\"After FGSM: {mse_fgsm:.6f}\")\n",
    "    print(f\"After PGD: {mse_pgd:.6f}\")\n",
    "    print(f\"FGSM Increase: {mse_fgsm/mse_original:.2f}x\")\n",
    "    print(f\"PGD Increase: {mse_pgd/mse_original:.2f}x\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45beb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
