{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14979459",
   "metadata": {},
   "source": [
    "# Fast Gradient Sign Method (FGSM) in AI Image Compression\n",
    "It is a *single-step* computationally efficient attack.  \n",
    "1. **Mathematical Formulations**\n",
    "The core idea is that to push the data into direction that **maximizes the loss function**. The formula that are used are:  \n",
    "$$x_{adv} = x+\\epsilon \\text{sign} (\\nabla_x J(\\theta, x, y)) =x+ \\frac{\\epsilon}{N}\\text{sign} (\\nabla_x \\|x- y\\|_F^2) $$\n",
    "where \n",
    "- $x$: The original, clean input image (a tensor of pixel values).  \n",
    "- $y=x_hat$: The decompressed of image $x$: $f(x)[{x_{hat}}]$, and $f$ is the compression model.  \n",
    "- $J(θ, x, y)$: The loss function (e.g., mse Loss) of the model.\n",
    "\n",
    "- $θ$: The parameters (weights) of the model. Crucially, these are held constant. We are not learning the model; we are attacking it.\n",
    "\n",
    "- $∇ₓ J(\\cdots)$: The gradient of the loss function with respect to the input image x. This tells us the direction in the input space that, if we follow it, will increase the loss the most.\n",
    "\n",
    "- $\\text{sign}(\\cdots)$: This function takes the gradient and converts each of its components to either +1, -1, or 0. This is done because we are only interested in the direction of the steepest ascent, not its magnitude. Using the sign also ensures that the perturbation for each pixel will be exactly +ε or -ε, which is optimal for the L∞ constraint.\n",
    "\n",
    "- $ε$ (epsilon): A small, scalar value that is the attack's \"budget.\" It defines the maximum amount any pixel is allowed to change. This keeps the perturbation imperceptible (on a [0,1] scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab21d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
